# asyncflows-language-server

default_model:
  model: ollama/llama3
flow:
  hello_world:
    action: prompt
    prompt:
      - text: Can you say hello world to {{ name }}
default_output: hello_world.result